<!DOCTYPE html>
<html lang="en">

<head>
    <title>VITA</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container" style="padding:20px">
            <div class="row align-items-center">
                <!-- <div class="col-12 col-lg-6 d-flex"> -->
                    <img src="./logo.png" width="15%">
                    <a class="ml-auto site-logo">
                       
                             &nbsp&nbsp<b style="color: rgb(71, 71, 71)">V</b>isual <b style="color: rgb(71, 71, 71)">I</b>nformatics Group @ University of <b style="color: rgb(71, 71, 71)">T</b>exas at <b style="color: rgb(71, 71, 71)">A</b>ustin
                    </a>
                    <a href="#"
                       class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"><span
                            class="icon-menu h3"></span></a>

                <!-- </div> -->
                <!-- <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                        <a href="#" class="d-inline-block p-3"> </a>
                    </div>

                </div> -->
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>

    
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container" style="padding-right=10%">
            <div class="d-flex align-items-right">
                <!-- <div class="mr-auto">
                    <a href="index.html">
                       <img src="./logo.png" width="10%"/>
                             &nbsp&nbsp<b>V</b>isual <b>I</b>nformatics Group @ University of <b>T</b>exas at <b>A</b>ustin
                    </a>
                </div> -->
                <div class="ml-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-right">Home</a>
                            </li>
                            <li>
                                <a href="research.html" class="nav-link text-left">PI & Research</a>
                            </li>
                            <li>
                                <a href="publication.html" class="nav-link text-left">Publication</a>
                            </li>
                            <li>
                                <a href="group.html" class="nav-link text-left">Group</a>
                            </li>
                            <li>
                                <a href="resource.html" class="nav-link text-left">Resource</a>
                            </li>
                            <li>
                                <a href="prospective_students.html" class="nav-link text-left">Opening</a>
                            </li>
                            <!-- <li class="nav-item dropdown">
                                              <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                   Challenge
                                 </a>
                                          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                           <a class="dropdown-item" href="challenge1.html">Tiny Object Detection Challenge</a>
                                           <a class="dropdown-item" href="challenge2.html">Image Restoration for UDC Challenge</a>
                                         </div>
                            </li>
                            <li>
                                <a href="callforpapers.html" class="nav-link text-left">Call for Papers</a>
                            </li>

                            <li>
                                <a href="speakers.html" class="nav-link text-left">Invited Speakers</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://yuqian2.wixsite.com/forlq">RLQ'19</a>
                                </div>
                            </li> -->
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>


<div class="site-blocks-cover " style="background-image: url('./background.jpg');"
     data-stellar-background-ratio="1">
    <div class="container">
        <div class="row align-items-center justify-content-center">
            <div class="col-md-10 text-center" data-aos="fade-up">

            </div>
        </div>
    </div>
</div>

<div class="site-section">
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="section-title" style="margin-bottom:20px">
                    <h2>News</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">

                        <b style="color:rgb(68, 68, 68)"><i>If you are here to seek "TL;DR"...</i></b>
                         <ul style="margin-bottom:5px">
                        <li><b style="color:rgb(71, 71, 71)">Question</b>: what should I read, if I just want to have a very quick glance at what VITA is currently digging on? </li> 
                        <li><b style="color:rgb(71, 71, 71)">Short Answer</b>: we pick five papers that represent our recent flavors as "chef's choice". The list will change over time: <a href="https://arxiv.org/abs/2306.14048">[Heavy-Hitter Oracle, NeurIPS 2023]</a>, <a href="https://arxiv.org/abs/2306.03805">[Essential Sparsity, NeurIPS 2023]</a> , <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_NeuralLift-360_Lifting_an_In-the-Wild_2D_Photo_to_a_3D_Object_CVPR_2023_paper.pdf">[NeuralLift-360, CVPR 2023]</a> , <a href="https://openreview.net/forum?id=cDYRS5iZ16f">[Learning to Grow LLMs, ICLR 2023]</a>, <a href="https://jmlr.org/papers/volume23/21-0308/21-0308.pdf">[Learning to Optimize, JMLR 2022]</a> 
                        </li> 
                        <li><b style="color:rgb(71, 71, 71)">Long Answer</b>: Please refer to our (still brief) <a href="research.html">Research Agenda</a> 
                        </li> 

                        <li><b style="color:rgb(71, 71, 71)">Follow VITA on Twitter!</b> Since April 2023, several VITA students volunteer to run a group Twitter (opinions on students' own): <a href="https://twitter.com/VITAGroupUT?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @VITAGroupUT</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8" data-size="large"></script>
                                            <p>
                    </ul>

                    <b style="color:rgb(68, 68, 68)">[Feb. 2024]</b>
                        <ul style="margin-bottom:5px">
                            <li> 7 CVPR'24 (Mode collapse in text-to-3D + Lift3D + Feature 3DGS + PAIR Diffusion + Zero-Painter + Prompt-Free Diffusion + OpenBias) accepted </li>  
                            <li> 2 MLSys'24 (Q-Hitter + formal verification LLM tuning) accepted </li>  
                    </ul>

                    <b style="color:rgb(68, 68, 68)">[Jan. 2024]</b>
                        <ul style="margin-bottom:5px">
                            <li>Our group co-organized the inaugural <a href="https://cpal.cc/"><b>Conference on Parsimony and Learning (CPAL)</b></a>, Hong Kong</li>
                            <li> 10 ICLR'24 (DP-OPT + LLM-KICK benchmark + Efficient-3DiM + hyperparameter scaling + DeepSet dimension + "vodka" distillation + graph diffusion + social reward + efficient watermarking + reweighted robust training) accepted </li> 
                            <li> 1 JAMIA (data-efficient electrocardiographic learning) accepted</li> 
                    </ul>


                    <b style="color:rgb(68, 68, 68)">[Dec. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 SatML'24 (generative model privacy) accepted</li> 
                            <li> 1 TMLR (MoE in contrastive learning) accepted</li>
                    </ul>

                    <b style="color:rgb(68, 68, 68)">[Nov. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 IEEE Trans. CAS-II (neuro-symbolic HW-SW co-design) accepted</li> 
                            <li> 4 CPAL'24 (block sparse training + sparsity in material science + GAN micromotion + WS-iFSD) accepted</li>
                    </ul>


                    <b style="color:rgb(68, 68, 68)">[Oct. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 IEEE Trans. PAMI (understanding NAS from DL theory) accepted</li> 
                            <li> 1 3DV'24 (few-shot 6D pose) accepted</li> 
                            <li> Our group co-organized the ICCV 2023 Workshop on  <a href="https://cvamd2023.github.io/">Computer Vision for Automated Medical Diagnosis (CVAMD)</a></li>
                    </ul>

                    <b style="color:rgb(68, 68, 68)">[Sep. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li>7 NeurIPS'23 (Essential sparsity + LLM heavy-hitter oracle + pruning topology + graph MoE + in-context diffusion + patch diffusion + channel-level DST) accepted </li> 
                            <li> VITA Postdoc <a href="https://shiweiliuiiiiiii.github.io/">Shiwei Liu</a> is selected to receive the prestigious Newton International Fellowship from the British Academy and the Royal Society</li> 
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Aug. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA welcomes four new Ph.D. students: Wes Robbins, Seo Young Lee, Zehao Zhu, and Runjin Chen</a> </li>
                            <li> 1 Nature Communications (medical imaging fairness) accepted</li> 
                            <li> 1 IEEE Trans. Image Processing (adaptive deblurring) accepted</li> 
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Jul. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li>8 ICCV'23 (GNT-MOVE + turbulence diffusion + vision HGNN + AdaMV-MoE + StegaNeRF + versatile diffusion + robust MoE + Text2Video-Zero) accepted </li> 
                            <li>1 QCE'23 (quantum sparse training) accepted </li> 
                            <li>2 ICCAD'23 (Edge-MoE + INR dataflow) accepted </li> 
                            <li>1 invited paper at IEEE Data Engineering Bulletin (graph contrastive learning)</li> 
                            <li> VITA Ph.D. students <a href="https://yifanjiang19.github.io/">Yifan Jiang</a> and <a href="https://gholste.me/">Greg Holste</a> are selected to receive two UT Graduate Dean’s Prestigious Fellowships
                        </ul>

                     <b style="color:rgb(68, 68, 68)">[Jun. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA Ph.D. student <a href="https://ajay1994.github.io/">Ajay Jaiswal</a>  is selected to receive the Inaugural Amazon Science Research Fellowship (by the UT-Amazon Hub)</a> </li>
                            <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/">Tianlong Chen</a> is selected to receive the AdvML Rising Star Award 2023</a> </li>
                            <li> 1 European Heart Journal (clinical SSL for echocardiography; IF = 35.855) accepted <a href="https://medicalxpress.com/news/2023-08-artificial-intelligence-automates-diagnosis-severe.html">[Press]</a> </li>
                            <li> 1 TMLR (deep image prior parameterization) accepted</li>
                             <li> 1 Information Fusion (transformer for traffic prediction) accepted</li>
                            <li> Our group co-organized the CVPR 2023 Workshop and Prize Challenge: <a href="http://cvpr2023.ug2challenge.org/">Bridging the Gap between Computational Photography and Visual Recognition (UG2+)</a></li>
                            <li> Our group co-organized the ICASSP 2023 Short Course on <a href="https://highdimdata-lowdimmodels-tutorial.github.io/">Learning Nonlinear and Deep Low-Dimensional Representations from High-Dimensional Data: From Theory to Practice</a></li>
                            <li> Our group co-organized the ICASSP 2023 Tutorial on Bilevel Optimization for Machine Learning: Theory, Algorithms and Applications</li>
                            <li> Our group co-organized the ICASSP 2023 Special Session on Unsupervised Deep Learning of Image Priors for Inverse Problems</li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[May. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA's Summer 2023 (big) squad of Ph.D. students graduated: 
                            <ul class="j">
                                <li> Dr. Tianlong Chen will join CS@UNC Chapel Hill as an Assistant Professor (starting from Fall 2024), after another year of postdoc at MIT/Harvard 
                                </li>
                                <li> Dr. Wuyang Chen will join CS@Simon Fraser as an Assistant Professor (starting from Fall 2024), after another year of postdoc at UC Berkeley
                                </li>
                                <li> Dr. Junru Wu joins Google Research, New York as a Research Engineer
                                </li>
                                <li> Dr. Haotao Wang joins Qualcomm AI Research, San Diego as a Research Scientist
                                </li>
                                <li> Dr. Ziyu Jiang joins NEC Labs America, CA as a Research Scientist
                                </li>
                                <li> Dr. Wenqing Zheng joins Amazon, CA as a Senior Applied Scientist
                                </li>
                                <li> Dr. Jiayi Shen joins Amazon, CA as an Applied Scientist
                                </li>
                                <li> Dr. Yan Han joins LinkedIn, CA as a Research Scientist
                                </li>
                            </ul>
                            Congratulations to ALL! 
                        </li>
                        <li> Announce the <a href="https://cpal.cc/">Conference on Parsimony and Learning (CPAL)</a>, a brand-new conference for the sparse ML research community, that Dr. Wang co-founds and will serve as its inaugural Program Chair</li> 
                        <li> 1 ACL'23 (sparse LLM tuning) accepted </li>
                        <li> 1 MICCAI'23 (multi-label long-tail) accepted </li>
                        <li> 1 AutoML-Conf'23 (neural architecture "no free lunch") accepted </li>
                        <li> 1 TMLR (partial graph transfer learning) accepted</li> 
                            <li> Our group co-organized the ICLR 2023 Workshop on <a href="https://www.sparseneural.net/">Sparsity in Neural Networks: On Practical Limitations and Tradeoffs between Sustainability and Efficiency</a></li>
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Apr. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li>9 ICML'23 (Instant soup + graph ladling + robust weight signature + neural scaling law + code generation + L2O game + large kernel teacher + pre-training tax + L2O math structure) accepted </li> 
                            <li> Dr. Wang is grateful to receive the 2023 Google Research Scholar Award</li>
                            <li> Our group co-organized the NSF IFML workshop on  <a href="https://ifml-uw.github.io/IFML-Workshop-2023/">Models v.s. Data in ML and AI</a></li>
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Mar. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA Ph.D. student <a href="https://gholste.me/">Greg Holste</a> is selected to receive a 2023 academic year NSF Graduate Research Fellowship (GRFP)</a> </li>
                            <li> 1 TMLR (pruning for certified robustness) accepted</li> 
                            <li> We thank MIT News <a href="https://news.mit.edu/2023/new-technique-machine-learning-models-0322">[article]</a> for covering our ICLR'23 work, <a href="https://openreview.net/forum?id=cDYRS5iZ16f">Learning to Grow Pretrained Models</a></li>      
                            <li> We thank 1littlecoder for the very cool video <a href="https://www.youtube.com/watch?v=97-1GYPtz0M">[Youtube]</a> highlighting our latest work, Text2Video-Zero (ICCV'23) <a href="https://arxiv.org/abs/2303.13439">[Paper]</a> <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero">[Code]</a> <a href="https://huggingface.co/spaces/PAIR/Text2Video-Zero">[Hugging Face]</a></li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Feb. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li> 4 CVPR'23 (NeuralLift-360 + AligNeRF + MMG-Ego4D + specialist diffusion) accepted</li> 
                            <li> 1 TMLR (robust fairness) accepted</li> 
                            <li> Dr. Wang is grateful to receive tenure promotion (effective Sep 2023)</li>
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Jan. 2023]</b>
                        <ul style="margin-bottom:5px">
                            <li>14 ICLR'23 (Ramanujan graph pruning + SMC benchmark + MoE as dropout + learning to grow + federated OoD + ConvNet 51x51 + GNT + NeRF-SOS + layered pre-training + HotProtein + hypergraph diffusion + graph domain adaptation + L2O adaptation + protein convolution) accepted </li> 
                            <li>2 AISTATS'23 (sparse network NTK + L2O generalization) accepted </li> 
                            <li> 1 IEEE Trans. Image Processing (A2I2 Real Haze benchmark) accepted</li>       
                            <li> We thank MattVidPro AI for the very cool video <a href="https://www.youtube.com/watch?v=Irx8NJYGF14">[Youtube]</a> highlighting our latest work, Versatile Diffusion (ICCV'23) <a href="https://arxiv.org/abs/2211.08332">[Paper]</a> <a href="https://github.com/SHI-Labs/Versatile-Diffusion">[Code]</a> <a href="https://huggingface.co/spaces/shi-labs/Versatile-Diffusion">[Hugging Face]</a></li> 
                            <li> We thank IEEE Signal Processing Society <a href="https://signalprocessingsociety.org/newsletter/2023/01/sps-webinar-18-january-2023-presented-mr-yifan-jiang">[Link]</a> for highlighting our IEEE TIP'21 work, EnlightenGAN <a href="https://ieeexplore.ieee.org/document/9334429">[Paper]</a> <a href="https://github.com/VITA-Group/EnlightenGAN">[Code]</a>, as one of SPS's top-25 most downloaded articles on IEEE Xplore®, 2021-2022</li> 
                            <li> Our group co-organized the 3rd Workshop on <a href="https://slowdnn-workshop.github.io/">Seeking Low-Dimensionality in Deep Neural Networks (SLowDNN)</a></li>
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Dec. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> We are grateful to receive the Best Paper Award from LoG 2022 <a href="https://openreview.net/forum?id=dF6aEW3_62O">[Paper]</a></li> 
                            <li> Dr. Wang is grateful to receive the IEEE biennial "AI's 10 To Watch" award in 2022</li>
                             <li> VITA Ph.D. student <a href="https://yifanjiang19.github.io/">Yifan Jiang</a> is selected to receive a 2022 academic year Apple Scholars in AI/ML PhD fellowship </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Nov. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA Ph.D. student <a href="https://ir1d.github.io/">Dejia Xu</a> is selected to receive a 2022 academic year Snap Research Fellowship </a> </li>
                            <li> Our group is selected to be supported by the Meta Reality Labs Research Gift Award </li>
                            <li> Our group is selected to be supported by the Google TensorFlow Model Garden Award (again) </li>
                            <li>3 AAAI'23 (safeguarded L2O + federated robustness + efficient ViT) accepted </li> 
                            <li>1 LoG'22 (untrained graph LTH) accepted </li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Oct. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 WSDM'23 (search behavior prediction) accepted </li> 
                            <li>1 WACV'23 (imbalance in medical image localization) accepted </li> 
                        </ul>

                     <b style="color:rgb(68, 68, 68)">[Sep. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li>11 NeurIPS'22 (DAG convergence + INR DSP theory + M<sup>3</sup>ViT + back razor + randomized channel shuffling + symbolic TCC + GCN gradient + trapping backdoor + multimodal training + sparse few-shot learning + hypergraph contrastive learning) accepted </li> 
                            <li>1 NeurIPS Benchmark Track'22 (large-scale graph training) accepted </li> 
                        </ul>

                     <b style="color:rgb(68, 68, 68)">[Aug. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA Ph.D. student <a href="https://zhiwenfan.github.io/">Zhiwen Fan</a> is selected to receive a 2022 academic year Qualcomm Innovation Fellowship (QIF) </a> </li>
                            <li> VITA welcomes six new Ph.D. students: Zhenyu Zhang, Tong Wang, S P Sharan, Ruisi Cai, Wenyan Cong, and Jeffrey Lai </a> </li>
                            <li> 1 IEEE Trans. Medical Imaging (contrastive learning on X-rays) accepted</li> 
                            <li> 1 TMLR (all-pass lottery) accepted</li> 
                            <li> 1 ICDM'22 (stochastic KD for medical imaging) accepted</li> 
                            <li> 1 CIKM'22 (multi-modal recommendation) accepted</li> 
                            <li> Our group co-organized MLSys 2022 Tutorial: <a href="https://mlsys.org/virtual/2022/tutorial/2201">Training-Free Approaches for Edge AI: Challenges, Opportunities and Progress</a></li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Jul. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 8 ECCV'22 (SinNeRF + INR stylization + scalable L2O + point cloud MAE + few-shot align + malleable convolution + universal ViT + turbulence) accepted</li> 
                            <li> 1 TMLR (adversarial feature augmentation) accepted</li> 
                            <li>VITA Ph.D. student Xiaohan Chen graduated and joined Alibaba Damo Academy (Decision Intelligence Lab), Seattle, as a full-time senior research scientist ("Ali Star" hire)</li>
                            <li> Our group co-organized the 2nd workshop on <a href="https://www.sparseneural.net/home"> Sparsity in Neural Networks: Advancing Understanding and Practice (SNN) </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Jun. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the NSF CAREER Award </li>
                            <li> Dr. Wang is grateful to receive the Aharon Katzir Young Investigator Award of International Neural Network Society (INNS) </li>
                            <li> 1 ACM Computing Surveys (ML safety) accepted</li> 
                            <li> 1 TMLR (robust lifelong learning) accepted</li> 
                            <li> 3 ACM MM'22 (controllable light enhancement + video action detection + Cloud2Sketch) accepted</li> 
                            <li> 1 ACM BCB'22 (pretraining for  COVID-19 prediction) accepted</li> 
                            <li> 1 MLHC'22 (personalized imbalanced training) accepted</li> 
                            <li> Our group co-organized the CVPR 2022 Workshop and Challenge on <a href="http://cvpr2022.ug2challenge.org">Bridging Computational Photography and Visual Recognition (UG2+)</a></li>
                            <li> Our group co-organized the AICAS 2022 tutorial: <a href="https://aicas2022.org/?page_id=192"> IEEE Low-Power Computer Vision Challenge</a>. A similar tutorial would be offered in DAC 2022</li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[May. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 9 ICML'22 (long-tail OoD detection + BN-free robust training + neural implicit dictionary + improved sparse training + linearity grafting + structured lottery ticket + double-win lottery ticket + renormalization group theory + NN architecture growing) accepted</li> 
                            <li> 1 AutoML-Conf'22 (GNN NAS) accepted</li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Apr. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 JMLR (learning to optimize) accepted</li> 
                            <li>1 IEEE Trans. PAMI (deep GCN training benchmark) accepted</li>
                            <li> 1 ACM FAccT'22 (data efficiency under differential privacy) accepted</li> 
                            <li> We thank IEEE Computer Magazine <a href="https://www.computer.org/csdl/magazine/co/2022/04/09755195/1Cubx6Twc5G">[article]</a> for covering our recent success in building <a href="https://lpcv.ai/scoreboard/Video21">energy-efficient computer vision systems</a></li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Mar. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> We thank Quanta Magazine <a href="https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/">[article]</a> for covering our NeurIPS'21 work, <a href="https://proceedings.neurips.cc/paper/2021/file/7c220a2091c26a7f5e9f1cfb099511e3-Paper.pdf">TransGAN</a></li>  
                            <li> We thank National Science Foundation (NSF) news <a href="https://www.nsf.gov/cise/news/NeuralArchitecture.pdf">[article]</a> for covering our training-free NAS works, in ICLR'21 (<a href="https://openreview.net/forum?id=Cnon5ezMHtu">TE-NAS</a>) and ICLR'22 (<a href="https://openreview.net/forum?id=H94a1_Pyr-6">As-ViT</a>)</li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Feb. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 7 CVPR'22 (ViT training + Aug-NeRF + symbolic spotting + sparsity for Trojan + sparse multi-tasking + video SR + fashion CLIP) accepted</li> 
                            <li> 1 IEEE Trans. Image Processing (light enhancement with noise) accepted</li> 
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Jan. 2022]</b>
                        <ul style="margin-bottom:5px">
                            <li> 14 ICLR'22 (symbolic L2O + disguised subnetwork + optimizer amalgamation + robust sparsity + Fourier ViT + auto-scaling ViT + ViT compression + Frank-Wolfe pruning + cold brew + audio lottery + split-max + sparse ensemble + random sparse training + Bayesian L2O) accepted </a> </li>
                            <li> 1 AISTATS'22 (variational feature selection) accepted </a> </li>
                            <li> 2 ICASSP'22 (lifelong speech synthesis + sensor data imputation) accepted </a> </li>
                            <li> 1 ACM Trans. DAES (efficient segmentation) accepted </a> </li>
                            <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/about/">Tianlong Chen</a> is selected to receive a 2022 academic year Adobe PhD Research Fellowship - that is after him being awarded IBM PhD Fellowship 2021, UT Graduate Dean’s Prestigious Fellowship 2021, and Baidu Scholarship finalist </a> </li>
                            <li> VITA welcomes four new Ph.D. students: Xuxi Chen, Dejia Xu, Hongru Yang and Zhangheng Li </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Dec. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> People in this group did nothing this month but enjoyed some well-deserved vacation time, with their families and loved ones </a> </li>
                        </ul>

                    <b style="color:rgb(68, 68, 68)">[Nov. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 IEEE Trans. Neural Networks and Learning Systems (algorithm-hardware co-design to reduce data movement) accepted </li>
                            <li> 1 AAAI'22 (federated sparse training) accepted </li>
                            <li> Our group co-organized the 2nd IEEE Workshop on <a href="https://sites.google.com/view/slowdnn2021/"> Seeking Low-dimensionality in Deep Neural Networks (SLowDNN)</a> </li>
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Oct. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 WSDM'22 (graph contrastive learning) accepted </li>
                            <li> 1 IEEE Trans. SPIN (vision-based drone swarm control) accepted </li>
                            <li> 3 WACV'22 (video NAS + sandwich BatchNorm +  chest X-rays) accepted </li>
                            <li> Our group is selected to be supported by the Google TensorFlow Model Garden Award </li>
                            <li> Our group co-organized the ICCV 2021 Workshop on <a href="https://rlq-workshop.github.io/">  Real-world Recognition from Low-quality Inputs (RLQ) </a> </li> 
                            <li> VITA Postdoctoral Researcher Dr. Guoliang Kang joins the CS department of University of Technology Sydney, Australia, as Lecturer (Assistant Professor) and endowed with the prestigious DECRA Fellow </a> </li> 
                            <li> We thank Henry for the very cool video <a href="https://www.youtube.com/watch?v=kQ09eg513Nc">[Youtube]</a> highlighting our latest work, AugMax (NeurIPS'21) <a href="https://arxiv.org/pdf/2110.13771.pdf">[Paper]</a> <a href="https://github.com/VITA-Group/AugMax">[Code]</a></li> 
                        </ul>


                    <b style="color:rgb(68, 68, 68)">[Sep. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li>13 NeurIPS'21 (TransGAN + AugMax + data-efficient GAN + elastic lottery ticket + SViTE + DePT + stealing lottery + imbalanced contrastive learning + HyperLISTA + WeakNAS + IA-RED<sup>2</sup> + neuroregeneration + lottery ticket benchmark) accepted </li>
                            <li>Our group won the 1st prize of <a href="https://lpcv.ai/scoreboard/Video21">IEEE 2021 Low-Power Computer Vision Challenge</a> (video track) <a href="https://github.com/VITA-Group/21LPCV-UAV-Solution"> [Solution] </a> <a href="https://arxiv.org/pdf/2204.04416.pdf"> [Tech Report] </a></li>
                            <li>1 ICCV'21 workshop (graph CNN for motion prediction) accepted</li>
                        </ul>



                     <b style="color:rgb(68, 68, 68)">[Aug. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA welcomes five new Ph.D. students: Zhiwen Fan, Scott Hoang, Peihao Wang, Greg Holste, and Ajay Jaiswal </a> </li>
                             <li>1 IEEE Trans. Image Processing (sketch-to-image synthesis) accepted</li> 
                             <li>1 Springer Machine Learning (weakly-supervised segmentation troubleshooting) accepted</li> 
                        </ul>


                          <b style="color:rgb(68, 68, 68)">[Jul. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 3 ICCV'21 (image harmonization + video NAS + pruning) accepted </li>
                            <li> Our group co-organized the inaugural workshop on <a href="https://www.sparseneural.net/ "> Sparsity in Neural Networks: Advancing Understanding and Practice (SNN) </a> </li>
                             <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/about/">Tianlong Chen</a> is selected to receive UT Graduate Dean’s Prestigious Fellowship, and <a href="http://www.xiaohanchen.com/">Xiaohan Chen</a>  is selected as a Qualcomm Innovation Fellowship 2021 finalist </li>
                        </ul>


                        <b style="color:rgb(68, 68, 68)">[Jun. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the 2021 J. P. Morgan Faculty Research Award </li>
                            <li>1 ACM ToMM (detecting GAN mode collapse) accepted</li>
                            <li>2 IEEE BHI'21 (meta learning for EHR data + MoE for EHR data) accepted</li>
                            <li> Our group co-organized the CVPR 2021 tutorial: <a href="https://vita-group.github.io/cvpr_2021_data_efficient_tutorial.html"> Data- and Label-Efficient Learning in An Imperfect World</a></li>   
                            <li>Our group co-organized two CVPR 2021 workshops:  <a href="http://cvpr2021.ug2challenge.org">Bridging Computational Photography and Visual Recognition (UG2+)</a>, and <a href="http://fvc-workshop.github.io">Future Video Conferencing (FVC) </a></li>
                            <li> We thank Henry for the very cool video <a href="https://www.youtube.com/watch?v=G3wjQEn0pQ0">[Youtube]</a> highlighting our latest work, self-damaging contrastive learning (ICML'21) <a href="https://arxiv.org/abs/2106.02990">[Paper]</a> <a href="https://github.com/VITA-Group/SDCLR">[Code]</a></li> 
                        </ul>


                          <b style="color:rgb(68, 68, 68)">[May. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> VITA's Summer 2021 squad of students graduated: Dr. Zhenyu Wu joined Wormpex AI Research (Seattle) as Research Scientist, Scott continues as VITA Ph.D. student, and Rahul joined ByteDance AI Lab (Silicon Valley) as Machine Learning Engineer. Congratulations! </li>
                            <li> 5 ICML'21 (graph contrastive learning + homotopy attack + imbalanced contrastive learning +  graph lottery ticket + data-efficient lottery ticket) accepted </li>
                            <li> 1 KDD'21 (federated learning debiasing) accepted </li>
                            <li> 1 ACL'21 (EarlyBERT) accepted </li>
                            <li> Our group is selected to be supported by the <a href="https://www.nvidia.com/en-us/industries/higher-education-research/applied-research-program/">NVIDIA Applied Research Accelerator Program</a> </li>
                        </ul>

                        <b style="color:rgb(68, 68, 68)">[Apr. 2021]</b>
                        <ul style="margin-bottom:5px">   
                            <li> VITA Ph.D. student <a href="https://tianlong-chen.github.io/about/">Tianlong Chen</a> is selected to receive a <a href="https://www.research.ibm.com/university/awards/fellowships-awardees.html">2021 academic year IBM PhD Fellowship</a> -- that is after Tianlong being selected as a Baidu Scholarship 2021 finalist </li>
                            <li>2 CVPR'21 workshop (CNN high-frequency bias + BN-free training of binary networks) accepted</li>
                        </ul>

                        <b style="color:rgb(68, 68, 68)">[Mar. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 1 ICME'21 (arbitrary style transfer) accepted </li>
                             <li> We thank UT Engineering News <a href="https://www.engr.utexas.edu/news/archive/9204-5-questions-with-cockrells-newest-machine-learning-and-artificial-intelligence-expert-atlas-wang">[article]</a> for highlighting our group's research </a></li>      
                        </ul>

                         <b style="color:rgb(68, 68, 68)">[Feb. 2021]</b>
                        <ul style="margin-bottom:5px">
                            <li> 3 CVPR'21 (CV lottery ticket + blind image IQA + assessing image enhancement) accepted </li>
                            <li>1 IJCV (open-world generalization of segmentation models) accepted</li>
                             <li> 1 DAC'21 + 1 ICASSP'21 accepted (InstantNet + VGAI)</a></li>  
                             <li> We thank Yannic for the very cool video <a href="https://www.youtube.com/watch?v=R5DiLFOMZrc&feature=youtu.be">[Youtube]</a> highlighting our latest work, TransGAN (NeurIPS'21) <a href="https://arxiv.org/abs/2102.07074">[Paper]</a> <a href="https://github.com/VITA-Group/TransGAN">[Code]</a></li>              
                        </ul>
                          <b style="color:rgb(68, 68, 68)">[Jan. 2021]</b>
                        <ul style="margin-bottom:5px">
                             <li>8 ICLR'21 (lifelong lottery ticket + robust overfitting + nasty knowledge distillation + theory-guided NAS + domain generalization + LISTA unrolling + learning to optimize for minimax + efficient recommendation system) accepted</li>
                             <li>1 IEEE Trans. PAMI (artistic text style transfer) accepted</li>
                            <li> We thank IDG Connect <a href="https://www.idgconnect.com/article/3602888/reducing-energy-use-in-neural-networks.html">[article]</a> for covering our ICLR'20 work, <a href="https://openreview.net/forum?id=BJxsrgStvr">Early Bird Lottery Ticket for Effcient Deep Learning </a></li>   
                            <li>Our group co-organized the <a href="https://sites.google.com/view/ijcai-boom2020/home?authuser=1/">IJCAI 2020 BOOM Workshop</a></li>
                            <li> VITA welcomes new Ph.D. student Wenqing Zheng</a></li>                    
                        </ul>
                             <b style="color:rgb(68, 68, 68)">[Dec. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 AAAI'21 (L2O for privacy protection) accepted</li>
                            <li>1 IEEE Trans. Image Processing (EnlightenGAN) accepted</li>
                            <li>1 Journal of Chemical Information and Modeling (explainable deep learning for bioinformatics) accepted</li>
                            <li> We thank MIT News <a href="https://news.mit.edu/2020/neural-model-language-1201">[article]</a> for covering our NeurIPS'20 work, <a href="https://proceedings.neurips.cc/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf">BERT Lottery Ticket Hypothesis </a></li>                           
                             <li> We thank US Army Research Lab for selecting our work of <a href="https://arxiv.org/abs/2002.02308">vision-based decentralized robotic control </a> as No. 3 in US ARL’s  <a href="https://www.army.mil/article/242136">“10 Coolest Techniques”</a> of Year 2020 [<a href="https://www.youtube.com/watch?v=6sg-4CxNbBk&feature=youtu.be&ab_channel=U.S.ArmyCCDCArmyResearchLaboratory">Video Demo</a>]
                             <li>Our group co-organized the <a href="https://www.hadr.ai">NeurIPS 2020 Workshop on AI for Humanitarian Assistance and Disaster Response (HADR)</a></li>
                             <li>VITA's Winter 2020 squad of M.S. students graduated: Ting-Kuei joined Qualcomm Research as Senior Deep Learning Engineer, Yunhe joined ByteDance AI Lab as Research Engineer, and Sicheng joined Walmart as Data Scientist. Congratulations!</a></li>
                        </ul>
                             <b style="color:rgb(68, 68, 68)">[Nov. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 IJCV (single image deraining benchmark) accepted</li>
                            <li>Our group co-organized the 1st IEEE Workshop on <a href="https://sites.google.com/view/slowdnn/">Seeking Low-dimensionality in Deep Neural Networks (SLowDNN)</a> <a href="https://www.youtube.com/playlist?from=timeline&list=PL7P834wcUN3eSh7Nn4wzPBjEnme4Rls7n&app=desktop">[video record]</a></li>
                            
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Oct. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>Our three popular image enhancement algorithms: AOD-Net (ICCV 2017), EnlightenGAN (IEEE TIP 2020), and DeblurGAN-V2 (ICCV 2019), are included into the open-source GNU Image Manipulation Program toolbox <a href="https://github.com/kritiksoman/GIMP-ML?fbclid=IwAR2ZcF0oKKItGQQFuxfvFxAfDOCW8FoEDISzkoFOmT130Vo7bQCcONJqbgg">(GIMP-ML)</a>, as <a href="https://www.youtube.com/watch?v=VWl6tyylO50&list=PLo9r5wFmpD5dRfeIthwuL52eNdXthRE7V&index=6&ab_channel=KritikSoman">deep-dehazing</a>, <a href="https://www.youtube.com/watch?v=SHrEWMWZ0dE&list=PLo9r5wFmpD5dRfeIthwuL52eNdXthRE7V&index=3&ab_channel=KritikSoman">enlighten</a>, and <a href="https://www.youtube.com/watch?v=adgHtu4chyU&list=PLo9r5wFmpD5dLWTyo6NOiD6BJjhfEOM5t&index=3&ab_channel=KritikSoman">deblur</a> plugins</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Sep. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the 2020 Adobe Data Science Research Award </li>
                            <li>8 NeurIPS'20 (learning to optimize + once-for-all adversarial training + BERT lottery ticket + meta learning + robust contrastive learning + graph contrastive learning + ShiftAddNet + efficient quantized training) accepted</li>
                            <li>1 IEEE Trans. PAMI (privacy-preserving visual recognition) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Aug. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>VITA's first Ph.D. student Ye Yuan graduated and joined ByteDance AI Lab, Silicon Valley, as a full-time researcher. A Memorable Point for both Ye and the group - Congratulations Ye!</li>
                            <li>Our group won the 2nd place of <a href="https://lpcv.ai/scoreboard/Video20">IEEE 2020 Low-Power Computer Vision Challenge</a> (video track)</li>
                            <li>Our group co-organized the <a href="https://rlq-tod.github.io">ECCV 2020 RLQ-TOD Workshop and Prize Challenge</a> <a href="https://www.youtube.com/playlist?list=PLPtQK8rJZ9HzU0ao9-Zdy-vmCc_Rw-9U8">[video record]</a></li>
                            <li>1 IEEE Trans. GRS (deep hyperspectral image classification) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Jul. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>3 ECCV'20 (GAN compression + sketch-to-image synthesis + on-device learning-to-optimize) accepted</li>
                            <li>1 ACM Multimedia'20 (MMHand synthesizer) accepted </li>
                               <li>1 InterSpeech'20 (AutoSpeech) accepted</li>
                            <li> We thank Tech Xplore <a href="https://techxplore.com/news/2020-07-deep-neural-networks-adversarial-d.html">[article]</a> for covering our work, <a href="https://arxiv.org/abs/2006.14655">adversarial 3-D logos </a></li>  
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Jun. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>6 ICML'20 (domain generalization + noisy label training + self-supervised GCN + DNN optimization + GAN compression + NAS for Bayesian models) accepted</li>
                            <li>Our group co-organized the <a href="www.ug2challenge.org">CVPR 2020 UG2+ Workshop and Prize Challenge</a></li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[May. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 IEEE Trans. PAMI (image enhancement for visual understanding) accepted</li>
                            <li> 1 IEEE Trans.  Mobile Computing (adaptive model compression) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Apr. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li> Dr. Wang is grateful to receive the 2020 ARO Young Investigator Award (YIP) </li>
                            <li> Dr. Wang is grateful to receive the 2020 IBM Faculty Research Award </li>
                            <li> Dr. Wang is grateful to receive the 2020 Amazon Research Award (AWS AI) </li>
                            <li>2 CVPR'20 workshop (efficient triplet loss + fine-grained classification) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Mar. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>1 ISCA'20 (algorithm-hardware co-design to reduce data movement) accepted</li>
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Feb. 2020]</b>
                        <ul style="margin-bottom:5px">
                            <li>3 CVPR'20 (self-supervised adversarial robustness + fast GCN training + indoor scene reasoning) accepted</li>
                            <li>1 IEEE Trans. Image Processing (visual understanding in poor-visibility environments) accepted</li>                           
                        </ul>
                        <b style="color:rgb(68, 68, 68)">[Jan. 2020]</b>
                        <ul>
                            <li>
                                 1 AISTATS'20 (CNN uncertainty quantification) accepted</li>
                                <li> 1 IEEE Trans. CSVT (GAN data augmentation) accepted 
                            </li>
                        </ul>
                    </div>
                </div>
            </div>


            

        <div class="col-lg-12" id="sponsor">
            <div class="section-title" style="padding-top: 50px">
                <h2>Sponsor</h2>
            </div>
            <div class="trend-entry d-flex">
                <div class="row justify-content-md-center">
                    <div>
                        <img src="./123.png" width="100%"/>
                    </div>
                </div>
            </div>
        </div>

        </div>
    </div>
</div>
        
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | Built upon <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        </p>
                        
                </div>
            </div>
        </div>
    </div>
</div>

</div>
<!-- .site-wrap -->


<!-- loader -->
<!-- <div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div> -->

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>

<script src="js/main.js"></script>

</body>

</html>
